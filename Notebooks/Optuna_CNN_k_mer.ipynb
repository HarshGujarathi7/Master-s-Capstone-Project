{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51cbcf98",
   "metadata": {},
   "source": [
    "## ðŸ§¬ CNN for TFBS Classification using k-mer Embeddings (Optuna-CNN-k-mer)\n",
    "\n",
    "This notebook presents a deep learning pipeline for classifying DNA sequences as transcription factor binding sites (TFBS) or non-TFBS using k-mer based tokenization. DNA sequences are first broken into overlapping k-mers, which are then embedded via a trainable embedding layer. A dynamic CNN architecture is constructed, where the number of convolutional layers, filter sizes, number of filters, activation functions, and dropout rates are treated as tunable hyperparameters.\n",
    "\n",
    "To automate and optimize the model architecture, the notebook employs Optuna, a powerful hyperparameter optimization framework. The objective function maximizes validation accuracy by searching across a defined hyperparameter space. The best-performing model is then saved for downstream inference.\n",
    "\n",
    "Overall, this approach combines domain-aware sequence preprocessing with automated architecture search to yield a tailored CNN model capable of learning motif patterns in genomic sequences for TFBS prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62612ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "\n",
    "from initialize_results_df import initialize_results_df\n",
    "from load_sequence_data import load_sequence_data\n",
    "from optuna_cnn_kmer_utils import *\n",
    "from k_mer_data_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b6790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "stride = 1\n",
    "embedding_dim = 64\n",
    "max_len = 96  # Could do 97: (101 - K + 1) // S = 97\n",
    "batch_size = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vocab = build_kmer_vocab(k)\n",
    "vocab_size = len(vocab) + 1\n",
    "data_dir = \"..\\\\Data\"\n",
    "excel_dir = \"..\\\\Outputs\\\\optuna_cnn_kmer.xlsx\"\n",
    "\n",
    "results_df, excel_df = initialize_results_df(data_dir, excel_dir)\n",
    "\n",
    "train_df = load_sequence_data(results_df[\"train_path\"][0])\n",
    "test_df = load_sequence_data(results_df[\"test_path\"][0])\n",
    "\n",
    "vocab = build_kmer_vocab(k)\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "train_loader, valid_loader, test_loader = prepare_kmer_loaders(\n",
    "    train_df[\"sequence\"].tolist(),\n",
    "    train_df[\"label\"].values,\n",
    "    test_df[\"sequence\"].tolist(),\n",
    "    test_df[\"label\"].values,\n",
    "    vocab,\n",
    "    k,\n",
    "    stride,\n",
    "    max_len,\n",
    "    batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b8e132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-04 02:29:43,871] A new study created in memory with name: no-name-ba9d4926-3ab2-4fb6-9b24-d4ecf9cb182f\n",
      "[I 2025-05-04 02:32:40,442] Trial 0 finished with value: 0.8894866704940796 and parameters: {'num_layers': 8, 'embedding_dim': 64, 'units_0': 64, 'kernel_size_0': 7, 'activation_0': 'silu', 'dropout_0': 0.4466458552647049, 'units_1': 128, 'kernel_size_1': 7, 'activation_1': 'relu', 'dropout_1': 0.37092693656724307, 'units_2': 32, 'kernel_size_2': 7, 'activation_2': 'silu', 'dropout_2': 0.48471193871923834, 'units_3': 64, 'kernel_size_3': 11, 'activation_3': 'relu', 'dropout_3': 0.41448445075946194, 'units_4': 128, 'kernel_size_4': 11, 'activation_4': 'gelu', 'dropout_4': 0.33867273953853816, 'units_5': 64, 'kernel_size_5': 7, 'activation_5': 'gelu', 'dropout_5': 0.17380016418959987, 'units_6': 32, 'kernel_size_6': 11, 'activation_6': 'gelu', 'dropout_6': 0.47288629320113895, 'units_7': 64, 'kernel_size_7': 5, 'activation_7': 'gelu', 'dropout_7': 0.3496816138430259}. Best is trial 0 with value: 0.8894866704940796.\n",
      "[I 2025-05-04 02:35:08,709] Trial 1 finished with value: 0.8800881505012512 and parameters: {'num_layers': 6, 'embedding_dim': 64, 'units_0': 128, 'kernel_size_0': 5, 'activation_0': 'silu', 'dropout_0': 0.27857101427927955, 'units_1': 128, 'kernel_size_1': 5, 'activation_1': 'relu', 'dropout_1': 0.2483171150068905, 'units_2': 64, 'kernel_size_2': 5, 'activation_2': 'relu', 'dropout_2': 0.22907934092377158, 'units_3': 32, 'kernel_size_3': 11, 'activation_3': 'gelu', 'dropout_3': 0.19246518655455092, 'units_4': 32, 'kernel_size_4': 11, 'activation_4': 'relu', 'dropout_4': 0.2513443203009649, 'units_5': 32, 'kernel_size_5': 5, 'activation_5': 'silu', 'dropout_5': 0.42032773807104395}. Best is trial 0 with value: 0.8894866704940796.\n",
      "[I 2025-05-04 02:37:22,382] Trial 2 finished with value: 0.8710137605667114 and parameters: {'num_layers': 5, 'embedding_dim': 64, 'units_0': 32, 'kernel_size_0': 5, 'activation_0': 'relu', 'dropout_0': 0.3213031568755274, 'units_1': 64, 'kernel_size_1': 7, 'activation_1': 'relu', 'dropout_1': 0.3550776960362877, 'units_2': 128, 'kernel_size_2': 5, 'activation_2': 'gelu', 'dropout_2': 0.14613753467679574, 'units_3': 64, 'kernel_size_3': 11, 'activation_3': 'gelu', 'dropout_3': 0.4829281718632975, 'units_4': 64, 'kernel_size_4': 5, 'activation_4': 'silu', 'dropout_4': 0.4804158776101012}. Best is trial 0 with value: 0.8894866704940796.\n",
      "[I 2025-05-04 02:40:15,586] Trial 3 finished with value: 0.8913015127182007 and parameters: {'num_layers': 8, 'embedding_dim': 64, 'units_0': 64, 'kernel_size_0': 7, 'activation_0': 'gelu', 'dropout_0': 0.23122437639607188, 'units_1': 64, 'kernel_size_1': 7, 'activation_1': 'gelu', 'dropout_1': 0.33485619074625783, 'units_2': 64, 'kernel_size_2': 7, 'activation_2': 'gelu', 'dropout_2': 0.4940536661996643, 'units_3': 64, 'kernel_size_3': 5, 'activation_3': 'relu', 'dropout_3': 0.465372944517808, 'units_4': 64, 'kernel_size_4': 7, 'activation_4': 'gelu', 'dropout_4': 0.22616799810160906, 'units_5': 128, 'kernel_size_5': 11, 'activation_5': 'silu', 'dropout_5': 0.24200228716258812, 'units_6': 128, 'kernel_size_6': 7, 'activation_6': 'relu', 'dropout_6': 0.22150719566813293, 'units_7': 64, 'kernel_size_7': 7, 'activation_7': 'relu', 'dropout_7': 0.20166024841073638}. Best is trial 3 with value: 0.8913015127182007.\n",
      "[I 2025-05-04 02:42:42,070] Trial 4 finished with value: 0.8854031562805176 and parameters: {'num_layers': 6, 'embedding_dim': 64, 'units_0': 32, 'kernel_size_0': 5, 'activation_0': 'gelu', 'dropout_0': 0.1460692550057977, 'units_1': 64, 'kernel_size_1': 5, 'activation_1': 'silu', 'dropout_1': 0.17036849678312516, 'units_2': 128, 'kernel_size_2': 7, 'activation_2': 'gelu', 'dropout_2': 0.36691213391982525, 'units_3': 64, 'kernel_size_3': 5, 'activation_3': 'relu', 'dropout_3': 0.21426852632497673, 'units_4': 32, 'kernel_size_4': 11, 'activation_4': 'silu', 'dropout_4': 0.2999084557918341, 'units_5': 32, 'kernel_size_5': 11, 'activation_5': 'silu', 'dropout_5': 0.1889596226558116}. Best is trial 3 with value: 0.8913015127182007.\n",
      "[I 2025-05-04 02:46:41,910] Trial 5 finished with value: 0.8957090973854065 and parameters: {'num_layers': 6, 'embedding_dim': 64, 'units_0': 32, 'kernel_size_0': 11, 'activation_0': 'gelu', 'dropout_0': 0.4412236033491853, 'units_1': 128, 'kernel_size_1': 7, 'activation_1': 'relu', 'dropout_1': 0.15430686710722163, 'units_2': 64, 'kernel_size_2': 5, 'activation_2': 'gelu', 'dropout_2': 0.23495445825315997, 'units_3': 32, 'kernel_size_3': 7, 'activation_3': 'gelu', 'dropout_3': 0.13135844759781748, 'units_4': 32, 'kernel_size_4': 11, 'activation_4': 'relu', 'dropout_4': 0.18943200152157363, 'units_5': 64, 'kernel_size_5': 11, 'activation_5': 'gelu', 'dropout_5': 0.2398955681564483}. Best is trial 5 with value: 0.8957090973854065.\n",
      "[I 2025-05-04 02:49:58,702] Trial 6 finished with value: 0.5055742859840393 and parameters: {'num_layers': 4, 'embedding_dim': 64, 'units_0': 64, 'kernel_size_0': 5, 'activation_0': 'silu', 'dropout_0': 0.12054660281435461, 'units_1': 128, 'kernel_size_1': 7, 'activation_1': 'gelu', 'dropout_1': 0.3000416026369227, 'units_2': 128, 'kernel_size_2': 11, 'activation_2': 'gelu', 'dropout_2': 0.4431737872450736, 'units_3': 32, 'kernel_size_3': 11, 'activation_3': 'silu', 'dropout_3': 0.16433815981868788}. Best is trial 5 with value: 0.8957090973854065.\n",
      "[I 2025-05-04 02:54:02,709] Trial 7 finished with value: 0.879375159740448 and parameters: {'num_layers': 6, 'embedding_dim': 64, 'units_0': 128, 'kernel_size_0': 5, 'activation_0': 'silu', 'dropout_0': 0.35255995245835825, 'units_1': 64, 'kernel_size_1': 7, 'activation_1': 'silu', 'dropout_1': 0.31825852316599407, 'units_2': 128, 'kernel_size_2': 5, 'activation_2': 'silu', 'dropout_2': 0.13409987714460356, 'units_3': 32, 'kernel_size_3': 7, 'activation_3': 'gelu', 'dropout_3': 0.38472682696420524, 'units_4': 64, 'kernel_size_4': 11, 'activation_4': 'gelu', 'dropout_4': 0.10035885950774648, 'units_5': 64, 'kernel_size_5': 7, 'activation_5': 'relu', 'dropout_5': 0.11358424718231426}. Best is trial 5 with value: 0.8957090973854065.\n",
      "[I 2025-05-04 02:58:04,372] Trial 8 finished with value: 0.8833938241004944 and parameters: {'num_layers': 6, 'embedding_dim': 64, 'units_0': 64, 'kernel_size_0': 11, 'activation_0': 'gelu', 'dropout_0': 0.17684817102976536, 'units_1': 128, 'kernel_size_1': 5, 'activation_1': 'gelu', 'dropout_1': 0.13881325088204532, 'units_2': 128, 'kernel_size_2': 5, 'activation_2': 'silu', 'dropout_2': 0.29857905847216626, 'units_3': 128, 'kernel_size_3': 5, 'activation_3': 'silu', 'dropout_3': 0.2765922740398182, 'units_4': 128, 'kernel_size_4': 5, 'activation_4': 'silu', 'dropout_4': 0.28203118116947123, 'units_5': 64, 'kernel_size_5': 7, 'activation_5': 'relu', 'dropout_5': 0.13914981332050866}. Best is trial 5 with value: 0.8957090973854065.\n",
      "[I 2025-05-04 03:02:07,018] Trial 9 finished with value: 0.5055742859840393 and parameters: {'num_layers': 6, 'embedding_dim': 64, 'units_0': 64, 'kernel_size_0': 7, 'activation_0': 'relu', 'dropout_0': 0.29677412991569363, 'units_1': 64, 'kernel_size_1': 5, 'activation_1': 'gelu', 'dropout_1': 0.38065862277592566, 'units_2': 128, 'kernel_size_2': 5, 'activation_2': 'relu', 'dropout_2': 0.44577948028204106, 'units_3': 32, 'kernel_size_3': 5, 'activation_3': 'relu', 'dropout_3': 0.12769094532309905, 'units_4': 128, 'kernel_size_4': 5, 'activation_4': 'gelu', 'dropout_4': 0.16590055680315796, 'units_5': 32, 'kernel_size_5': 5, 'activation_5': 'relu', 'dropout_5': 0.29358809792492047}. Best is trial 5 with value: 0.8957090973854065.\n",
      "[I 2025-05-04 03:05:19,941] Trial 10 finished with value: 0.8907830119132996 and parameters: {'num_layers': 4, 'embedding_dim': 64, 'units_0': 32, 'kernel_size_0': 11, 'activation_0': 'gelu', 'dropout_0': 0.4893843534483254, 'units_1': 32, 'kernel_size_1': 11, 'activation_1': 'relu', 'dropout_1': 0.47233582987719264, 'units_2': 64, 'kernel_size_2': 11, 'activation_2': 'gelu', 'dropout_2': 0.2481336502306162, 'units_3': 128, 'kernel_size_3': 7, 'activation_3': 'gelu', 'dropout_3': 0.293779884532966}. Best is trial 5 with value: 0.8957090973854065.\n",
      "[I 2025-05-04 03:10:02,684] Trial 11 finished with value: 0.4944257140159607 and parameters: {'num_layers': 8, 'embedding_dim': 64, 'units_0': 32, 'kernel_size_0': 7, 'activation_0': 'gelu', 'dropout_0': 0.21213207358131114, 'units_1': 32, 'kernel_size_1': 7, 'activation_1': 'gelu', 'dropout_1': 0.22870325246346912, 'units_2': 64, 'kernel_size_2': 7, 'activation_2': 'gelu', 'dropout_2': 0.36213956924750984, 'units_3': 64, 'kernel_size_3': 7, 'activation_3': 'relu', 'dropout_3': 0.3656723462316177, 'units_4': 64, 'kernel_size_4': 7, 'activation_4': 'relu', 'dropout_4': 0.1942631610215199, 'units_5': 128, 'kernel_size_5': 11, 'activation_5': 'gelu', 'dropout_5': 0.2742503180056518, 'units_6': 128, 'kernel_size_6': 7, 'activation_6': 'relu', 'dropout_6': 0.14515307956065582, 'units_7': 128, 'kernel_size_7': 7, 'activation_7': 'relu', 'dropout_7': 0.12232256557477651}. Best is trial 5 with value: 0.8957090973854065.\n",
      "[I 2025-05-04 03:15:35,538] Trial 12 finished with value: 0.890458881855011 and parameters: {'num_layers': 7, 'embedding_dim': 64, 'units_0': 64, 'kernel_size_0': 11, 'activation_0': 'gelu', 'dropout_0': 0.41643392631576254, 'units_1': 128, 'kernel_size_1': 11, 'activation_1': 'relu', 'dropout_1': 0.10621169031195116, 'units_2': 64, 'kernel_size_2': 7, 'activation_2': 'gelu', 'dropout_2': 0.21013006130733564, 'units_3': 32, 'kernel_size_3': 7, 'activation_3': 'gelu', 'dropout_3': 0.4944949540325994, 'units_4': 32, 'kernel_size_4': 7, 'activation_4': 'relu', 'dropout_4': 0.18921649584310363, 'units_5': 128, 'kernel_size_5': 11, 'activation_5': 'silu', 'dropout_5': 0.2515156378499342, 'units_6': 128, 'kernel_size_6': 7, 'activation_6': 'silu', 'dropout_6': 0.228379801773849}. Best is trial 5 with value: 0.8957090973854065.\n",
      "[I 2025-05-04 03:17:40,875] Trial 13 finished with value: 0.8873476982116699 and parameters: {'num_layers': 7, 'embedding_dim': 64, 'units_0': 32, 'kernel_size_0': 11, 'activation_0': 'gelu', 'dropout_0': 0.22576252459342533, 'units_1': 64, 'kernel_size_1': 7, 'activation_1': 'gelu', 'dropout_1': 0.4480619277552751, 'units_2': 64, 'kernel_size_2': 7, 'activation_2': 'gelu', 'dropout_2': 0.33566003454054705, 'units_3': 64, 'kernel_size_3': 5, 'activation_3': 'relu', 'dropout_3': 0.24302186472639065, 'units_4': 64, 'kernel_size_4': 7, 'activation_4': 'relu', 'dropout_4': 0.39533226837796687, 'units_5': 128, 'kernel_size_5': 11, 'activation_5': 'gelu', 'dropout_5': 0.3875432235561647, 'units_6': 64, 'kernel_size_6': 5, 'activation_6': 'relu', 'dropout_6': 0.35478553325705553}. Best is trial 5 with value: 0.8957090973854065.\n",
      "[I 2025-05-04 03:19:46,804] Trial 14 finished with value: 0.4944257140159607 and parameters: {'num_layers': 7, 'embedding_dim': 64, 'units_0': 128, 'kernel_size_0': 7, 'activation_0': 'gelu', 'dropout_0': 0.38693829608792285, 'units_1': 32, 'kernel_size_1': 7, 'activation_1': 'silu', 'dropout_1': 0.22180642467363212, 'units_2': 32, 'kernel_size_2': 11, 'activation_2': 'gelu', 'dropout_2': 0.2876162466921981, 'units_3': 128, 'kernel_size_3': 5, 'activation_3': 'silu', 'dropout_3': 0.10098855117087992, 'units_4': 32, 'kernel_size_4': 7, 'activation_4': 'gelu', 'dropout_4': 0.10068883284886646, 'units_5': 64, 'kernel_size_5': 11, 'activation_5': 'gelu', 'dropout_5': 0.4987706842745497, 'units_6': 128, 'kernel_size_6': 7, 'activation_6': 'relu', 'dropout_6': 0.11301894793854725}. Best is trial 5 with value: 0.8957090973854065.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_layers': 6, 'embedding_dim': 64, 'units_0': 32, 'kernel_size_0': 11, 'activation_0': 'gelu', 'dropout_0': 0.4412236033491853, 'units_1': 128, 'kernel_size_1': 7, 'activation_1': 'relu', 'dropout_1': 0.15430686710722163, 'units_2': 64, 'kernel_size_2': 5, 'activation_2': 'gelu', 'dropout_2': 0.23495445825315997, 'units_3': 32, 'kernel_size_3': 7, 'activation_3': 'gelu', 'dropout_3': 0.13135844759781748, 'units_4': 32, 'kernel_size_4': 11, 'activation_4': 'relu', 'dropout_4': 0.18943200152157363, 'units_5': 64, 'kernel_size_5': 11, 'activation_5': 'gelu', 'dropout_5': 0.2398955681564483}\n",
      "0.8898755311965942\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    \"num_layers\": {\"type\": \"int\", \"low\": 4, \"high\": 8},\n",
    "    \"embedding_dim\": {\"type\": \"categorical\", \"choices\": [64]},\n",
    "    \"units\": {\"type\": \"categorical\", \"choices\": [32, 64, 128]},\n",
    "    \"kernel_size\": {\"type\": \"categorical\", \"choices\": [5, 7, 11]},\n",
    "    \"activation\": {\"type\": \"categorical\", \"choices\": [\"relu\", \"gelu\", \"silu\"]},\n",
    "    \"dropout\": {\"type\": \"float\", \"low\": 0.1, \"high\": 0.5},\n",
    "}\n",
    "\n",
    "best_model, best_params, acc, study = run_optuna_pipeline(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    vocab_size=len(vocab) + 1,\n",
    "    device=\"cuda\",\n",
    "    epochs=10,\n",
    "    n_trials=15,\n",
    "    max_len=96,\n",
    "    save_path=\"../Models/best_model_kmer.pt\",\n",
    "    search_space=search_space,\n",
    ")\n",
    "\n",
    "print(best_params)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3122e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params\n",
    "import json\n",
    "\n",
    "with open(\"../Models/final_model_hparams.json\", \"w\") as f:\n",
    "    json.dump(study.best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce83ac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_22820\\1109353383.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(\"../Models/best_model_kmer.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8878\n"
     ]
    }
   ],
   "source": [
    "# âœ… Load the saved best model weights\n",
    "best_model.load_state_dict(torch.load(\"../Models/best_model_kmer.pt\"))\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "\n",
    "# âœ… Evaluate on test_loader\n",
    "acc_test, preds_test, labels_test = evaluate(best_model, test_loader, device)\n",
    "\n",
    "print(f\"Test Accuracy: {acc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bda529",
   "metadata": {},
   "source": [
    "## Looping through 50 folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99d0f963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved at: ../Outputs/50_CNN_KM.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "data_dir = \"../Data\"\n",
    "excel_path = \"../Outputs/50_CNN_KM.xlsx\"\n",
    "\n",
    "# Load dataframes\n",
    "results_df, excel_df = initialize_results_df(data_dir, excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed5d70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hp from JSON\n",
    "with open(\"../Models/final_model_hparams.json\", \"r\") as f:\n",
    "    hp = json.load(f)\n",
    "\n",
    "if \"embedding_dim\" not in hp:\n",
    "    hp[\"embedding_dim\"] = 64  # or whatever value you tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df6b960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded and ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_22820\\233208746.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../Models/best_model_kmer.pt'))\n"
     ]
    }
   ],
   "source": [
    "vocab = build_kmer_vocab(k=5)\n",
    "vocab_size = len(vocab) + 1  # +1 for padding\n",
    "max_len = 101  # or fixed, or largest length across all folders (up to you)\n",
    "\n",
    "model = DynamicCNN(vocab_size, hp, max_len=max_len)\n",
    "model.load_state_dict(torch.load(\"../Models/best_model_kmer.pt\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"âœ… Model loaded and ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a079daf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadDnd41CtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadDnd41CtcfUniPk: train_acc=0.8460, test_acc=0.8268\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadDnd41Ezh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadDnd41Ezh239875UniPk: train_acc=0.6474, test_acc=0.5529\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadGm12878CtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadGm12878CtcfUniPk: train_acc=0.8736, test_acc=0.8411\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadGm12878Ezh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadGm12878Ezh239875UniPk: train_acc=0.6510, test_acc=0.5855\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadH1hescChd1a301218aUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadH1hescChd1a301218aUniPk: train_acc=0.6321, test_acc=0.5988\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadH1hescCtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadH1hescCtcfUniPk: train_acc=0.9014, test_acc=0.8788\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadH1hescEzh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadH1hescEzh239875UniPk: train_acc=0.6536, test_acc=0.5891\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadH1hescJarid1aab26049UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadH1hescJarid1aab26049UniPk: train_acc=0.6963, test_acc=0.6381\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadH1hescRbbp5a300109aUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadH1hescRbbp5a300109aUniPk: train_acc=0.6732, test_acc=0.6331\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHelas3CtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHelas3CtcfUniPk: train_acc=0.8888, test_acc=0.8638\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHelas3Ezh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHelas3Ezh239875UniPk: train_acc=0.6646, test_acc=0.6113\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHelas3Pol2bUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHelas3Pol2bUniPk: train_acc=0.6893, test_acc=0.6360\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHepg2CtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHepg2CtcfUniPk: train_acc=0.9351, test_acc=0.9098\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHepg2Ezh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHepg2Ezh239875UniPk: train_acc=0.6564, test_acc=0.5898\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHmecCtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHmecCtcfUniPk: train_acc=0.9478, test_acc=0.9272\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHmecEzh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHmecEzh239875UniPk: train_acc=0.6544, test_acc=0.6047\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHsmmCtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHsmmCtcfUniPk: train_acc=0.9382, test_acc=0.9139\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHsmmEzh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHsmmEzh239875UniPk: train_acc=0.6404, test_acc=0.5568\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHsmmtCtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHsmmtCtcfUniPk: train_acc=0.9241, test_acc=0.9092\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHsmmtEzh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHsmmtEzh239875UniPk: train_acc=0.6468, test_acc=0.5903\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHuvecCtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHuvecCtcfUniPk: train_acc=0.9447, test_acc=0.9257\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHuvecEzh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHuvecEzh239875UniPk: train_acc=0.6641, test_acc=0.6343\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadHuvecPol2bUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadHuvecPol2bUniPk: train_acc=0.7175, test_acc=0.6631\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadK562Chd1a301218aUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadK562Chd1a301218aUniPk: train_acc=0.6736, test_acc=0.6294\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadK562CtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadK562CtcfUniPk: train_acc=0.8962, test_acc=0.8724\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadK562Ezh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadK562Ezh239875UniPk: train_acc=0.6766, test_acc=0.6190\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadK562Hdac1sc6298UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadK562Hdac1sc6298UniPk: train_acc=0.6950, test_acc=0.6519\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadK562Hdac2a300705aUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadK562Hdac2a300705aUniPk: train_acc=0.6987, test_acc=0.6613\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadK562Hdac6a301341aUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadK562Hdac6a301341aUniPk: train_acc=0.7127, test_acc=0.6427\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadK562P300UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadK562P300UniPk: train_acc=0.6859, test_acc=0.6635\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadK562Phf8a301772aUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadK562Phf8a301772aUniPk: train_acc=0.7038, test_acc=0.6856\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadK562Plu1UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadK562Plu1UniPk: train_acc=0.7207, test_acc=0.6989\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadK562Pol2bUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadK562Pol2bUniPk: train_acc=0.7178, test_acc=0.6942\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadK562Rbbp5a300109aUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadK562Rbbp5a300109aUniPk: train_acc=0.7252, test_acc=0.6821\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadK562Sap3039731UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadK562Sap3039731UniPk: train_acc=0.7269, test_acc=0.6990\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadNhaCtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadNhaCtcfUniPk: train_acc=0.9438, test_acc=0.9242\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadNhaEzh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadNhaEzh239875UniPk: train_acc=0.7126, test_acc=0.6840\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadNhdfadCtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadNhdfadCtcfUniPk: train_acc=0.9418, test_acc=0.9255\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadNhdfadEzh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadNhdfadEzh239875UniPk: train_acc=0.7089, test_acc=0.6644\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadNhekCtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadNhekCtcfUniPk: train_acc=0.9332, test_acc=0.9174\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadNhekEzh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadNhekEzh239875UniPk: train_acc=0.6947, test_acc=0.6547\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadNhekPol2bUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadNhekPol2bUniPk: train_acc=0.7037, test_acc=0.6561\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadNhlfCtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadNhlfCtcfUniPk: train_acc=0.9354, test_acc=0.9236\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadNhlfEzh239875UniPk\n",
      "âœ… wgEncodeAwgTfbsBroadNhlfEzh239875UniPk: train_acc=0.7027, test_acc=0.6526\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsBroadOsteoblCtcfUniPk\n",
      "âœ… wgEncodeAwgTfbsBroadOsteoblCtcfUniPk: train_acc=0.9202, test_acc=0.9074\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsHaibA549Atf3V0422111Etoh02UniPk\n",
      "âœ… wgEncodeAwgTfbsHaibA549Atf3V0422111Etoh02UniPk: train_acc=0.7256, test_acc=0.6953\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsHaibA549Bcl3V0422111Etoh02UniPk\n",
      "âœ… wgEncodeAwgTfbsHaibA549Bcl3V0422111Etoh02UniPk: train_acc=0.7356, test_acc=0.7082\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsHaibA549Creb1sc240V0416102Dex100nmUniPk\n",
      "âœ… wgEncodeAwgTfbsHaibA549Creb1sc240V0416102Dex100nmUniPk: train_acc=0.7621, test_acc=0.7550\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsHaibA549Ctcfsc5916Pcr1xDex100nmUniPk\n",
      "âœ… wgEncodeAwgTfbsHaibA549Ctcfsc5916Pcr1xDex100nmUniPk: train_acc=0.9659, test_acc=0.9591\n",
      "ðŸ”„ Processing wgEncodeAwgTfbsHaibA549Ctcfsc5916Pcr1xEtoh02UniPk\n",
      "âœ… wgEncodeAwgTfbsHaibA549Ctcfsc5916Pcr1xEtoh02UniPk: train_acc=0.9669, test_acc=0.9572\n",
      "EXCEL SAVEd TO (excel_path)\n",
      "âœ… Final model saved!\n"
     ]
    }
   ],
   "source": [
    "for idx, row in results_df.iloc[:50].iterrows():\n",
    "    train_path = row[\"train_path\"]\n",
    "    test_path = row[\"test_path\"]\n",
    "    folder_name = row[\"folder_name\"]\n",
    "\n",
    "    print(f\"ðŸ”„ Processing {folder_name}\")\n",
    "\n",
    "    # --- Load data ---\n",
    "    train_df = load_sequence_data(train_path)\n",
    "    test_df = load_sequence_data(test_path)\n",
    "\n",
    "    # --- Tokenize ---\n",
    "    X_train = [\n",
    "        tokenize_sequence(seq, vocab, k=5, stride=2)\n",
    "        for seq in train_df[\"sequence\"]\n",
    "    ]\n",
    "    X_test = [\n",
    "        tokenize_sequence(seq, vocab, k=5, stride=2)\n",
    "        for seq in test_df[\"sequence\"]\n",
    "    ]\n",
    "    y_train = train_df[\"label\"].tolist()\n",
    "    y_test = test_df[\"label\"].tolist()\n",
    "\n",
    "    # --- Compute max_len dynamically (or set fixed if preferred) ---\n",
    "    max_len = max(\n",
    "        max(len(seq) for seq in X_train), max(len(seq) for seq in X_test)\n",
    "    )\n",
    "\n",
    "    # --- Prepare datasets/loaders ---\n",
    "    train_dataset = PreTokenizedDataset(X_train, y_train, max_len=max_len)\n",
    "    test_dataset = PreTokenizedDataset(X_test, y_test, max_len=max_len)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=32, shuffle=True\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    # --- Fine-tune same model ---\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "    # --- Evaluate ---\n",
    "    train_acc, train_preds, train_labels = evaluate(\n",
    "        model, train_loader, device\n",
    "    )\n",
    "    test_acc, test_preds, test_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "    # Optional: calculate PR AUC, ROC AUC\n",
    "    from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "    train_probs = train_preds.numpy()\n",
    "    test_probs = test_preds.numpy()\n",
    "\n",
    "    train_pr_auc = average_precision_score(train_labels.numpy(), train_probs)\n",
    "    train_roc_auc = roc_auc_score(train_labels.numpy(), train_probs)\n",
    "\n",
    "    test_pr_auc = average_precision_score(test_labels.numpy(), test_probs)\n",
    "    test_roc_auc = roc_auc_score(test_labels.numpy(), test_probs)\n",
    "\n",
    "    # âœ… Log metrics\n",
    "    excel_df.at[idx, \"train_accuracy\"] = train_acc\n",
    "    excel_df.at[idx, \"test_accuracy\"] = test_acc\n",
    "    excel_df.at[idx, \"pr-roc\"] = test_roc_auc\n",
    "    excel_df.at[idx, \"pr-auc\"] = test_pr_auc\n",
    "\n",
    "    print(\n",
    "        f\"âœ… {folder_name}: train_acc={train_acc:.4f}, test_acc={test_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "excel_df.iloc[: idx + 1].to_excel(excel_path, index=False)\n",
    "print(f\"EXCEL SAVEd TO (excel_path)\")\n",
    "\n",
    "# # âœ… Save final model\n",
    "torch.save(model.state_dict(), \"../Models/Cnn_kmer_50.pt\")\n",
    "print(\"âœ… Final model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2cdf4f",
   "metadata": {},
   "source": [
    "## User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df93b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "\n",
    "from optuna_cnn_kmer_utils import (\n",
    "    build_kmer_vocab,\n",
    "    load_optuna_cnn_kmer_model,\n",
    "    predict_optuna_cnn_kmer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28b4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "stride = 1\n",
    "max_len = 96\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98f6556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\Downloads\\CAPSTONE-PROJECT\\Notebooks\\../utils\\optuna_cnn_kmer_utils.py:263: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "vocab = build_kmer_vocab(k=k)\n",
    "\n",
    "model_path = \"../Models/best_model_kmer.pt\"\n",
    "config_path = \"../Models/final_model_hparams.json\"\n",
    "\n",
    "model, hp = load_optuna_cnn_kmer_model(\n",
    "    model_path, config_path, vocab_size=len(vocab) + 1, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be03cfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: TFBS (Confidence: 99.98%)\n"
     ]
    }
   ],
   "source": [
    "sequence = input(\"Enter a DNA sequence: \").strip()\n",
    "label, confidence = predict_optuna_cnn_kmer(\n",
    "    sequence, model, vocab, k=k, stride=stride, max_len=max_len, device=device\n",
    ")\n",
    "\n",
    "print(f\"Prediction: {label} (Confidence: {confidence}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae9f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
