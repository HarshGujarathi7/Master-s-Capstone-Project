{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa51d3f3",
   "metadata": {},
   "source": [
    "## ðŸ§¬ k-mer Embedding via Word2Vec for Genomic Sequences\n",
    "\n",
    "This notebook demonstrates the use of Word2Vec to learn vector representations (embeddings) of k-mers from DNA sequences. K-mers are substrings of fixed length extracted from sequences using a sliding window, mimicking the way words are tokenized in NLP.\n",
    "\n",
    "The skip-gram model of Word2Vec is used to train embeddings that capture the contextual similarity between k-mers based on their occurrence in biological sequences. The trained embedding vectors are then visualized using PCA to reveal patterns or clustering among similar k-mers.\n",
    "\n",
    "These learned k-mer embeddings are biologically meaningful and can be used as input features in downstream classification models like CNNs or gradient-boosted trees. The notebook lays the foundation for transforming symbolic DNA sequences into dense, semantically rich numerical representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9967ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from k_mer_data_loader import prepare_kmer_loaders\n",
    "from initialize_results_df import initialize_results_df\n",
    "from load_sequence_data import load_sequence_data\n",
    "from kmer_2_vec import (\n",
    "    get_kmer_list,\n",
    "    train_word2vec,\n",
    "    build_vocab,\n",
    "    build_embedding_matrix,\n",
    ")\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from kmer_2_vec import SimpleCNN, train_and_evaluate\n",
    "\n",
    "\n",
    "w2v_model = Word2Vec.load(\"../Models/kmer2vec_k_6_s_1.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "183c9001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Word2Vec Model!\n",
    "\n",
    "# file_path = \"C:/Users/dhair/Desktop/Captstone-Proj/Data/Data_3/global_train.data\"\n",
    "# df = load_sequence_data(file_path)\n",
    "# corpus = get_kmer_list(df['seq'].tolist(), k=6, stride=1)\n",
    "# w2v_model = train_word2vec(corpus)\n",
    "# w2v_model.save(\"../Outputs/kmer2vec_k_6_s_1.model\")\n",
    "# vocab = build_vocab(k=6)\n",
    "# pretrained_embeddings = {kmer: w2v_model.wv[kmer] for kmer in w2v_model.wv.index_to_key}\n",
    "# embedding_matrix = build_embedding_matrix(vocab, pretrained_embeddings, embedding_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(k=6)\n",
    "\n",
    "pretrained_embeddings = {\n",
    "    kmer: w2v_model.wv[kmer] for kmer in w2v_model.wv.index_to_key\n",
    "}\n",
    "embedding_matrix = build_embedding_matrix(\n",
    "    vocab, pretrained_embeddings, embedding_dim=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ef6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"..\\\\Data\"\n",
    "excel_dir = \"..\\\\Outputs\\\\excel_results.xlsx\"\n",
    "\n",
    "results_df, excel_df = initialize_results_df(data_dir, excel_dir)\n",
    "\n",
    "train_df = load_sequence_data(results_df[\"train_path\"][1])\n",
    "test_df = load_sequence_data(results_df[\"test_path\"][1])\n",
    "\n",
    "train_loader, valid_loader, test_loader = prepare_kmer_loaders(\n",
    "    train_df[\"sequence\"].tolist(),\n",
    "    train_df[\"label\"].values,\n",
    "    test_df[\"sequence\"].tolist(),\n",
    "    test_df[\"label\"].values,\n",
    "    vocab,\n",
    "    k=6,\n",
    "    stride=1,\n",
    "    max_len=96,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89083eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Epoch 1/10 started...\n",
      "ðŸ“ˆ Epoch 1/10 | Train Loss: 0.7803 | Train Acc: 0.5466 | Val Loss: 0.6934 | Val Acc: 0.5522 | Val ROC-AUC: 0.6133\n",
      "ðŸ”„ Epoch 2/10 started...\n",
      "ðŸ“ˆ Epoch 2/10 | Train Loss: 0.5885 | Train Acc: 0.6940 | Val Loss: 0.7072 | Val Acc: 0.5690 | Val ROC-AUC: 0.6378\n",
      "ðŸ”„ Epoch 3/10 started...\n",
      "ðŸ“ˆ Epoch 3/10 | Train Loss: 0.4915 | Train Acc: 0.7738 | Val Loss: 0.6548 | Val Acc: 0.6381 | Val ROC-AUC: 0.6880\n",
      "ðŸ”„ Epoch 4/10 started...\n",
      "ðŸ“ˆ Epoch 4/10 | Train Loss: 0.3994 | Train Acc: 0.8307 | Val Loss: 0.6623 | Val Acc: 0.6325 | Val ROC-AUC: 0.6893\n",
      "ðŸ”„ Epoch 5/10 started...\n",
      "ðŸ“ˆ Epoch 5/10 | Train Loss: 0.3334 | Train Acc: 0.8708 | Val Loss: 0.6828 | Val Acc: 0.6343 | Val ROC-AUC: 0.6868\n",
      "ðŸ”„ Epoch 6/10 started...\n",
      "ðŸ“ˆ Epoch 6/10 | Train Loss: 0.2586 | Train Acc: 0.9053 | Val Loss: 0.7409 | Val Acc: 0.6306 | Val ROC-AUC: 0.6667\n",
      "ðŸ”„ Epoch 7/10 started...\n",
      "ðŸ“ˆ Epoch 7/10 | Train Loss: 0.2079 | Train Acc: 0.9328 | Val Loss: 0.7761 | Val Acc: 0.6381 | Val ROC-AUC: 0.6679\n",
      "ðŸ”„ Epoch 8/10 started...\n",
      "ðŸ“ˆ Epoch 8/10 | Train Loss: 0.1561 | Train Acc: 0.9482 | Val Loss: 0.8052 | Val Acc: 0.6213 | Val ROC-AUC: 0.6779\n",
      "ðŸ”„ Epoch 9/10 started...\n",
      "ðŸ“ˆ Epoch 9/10 | Train Loss: 0.1264 | Train Acc: 0.9618 | Val Loss: 0.8754 | Val Acc: 0.6157 | Val ROC-AUC: 0.6700\n",
      "ðŸ”„ Epoch 10/10 started...\n",
      "ðŸ“ˆ Epoch 10/10 | Train Loss: 0.1144 | Train Acc: 0.9655 | Val Loss: 0.9371 | Val Acc: 0.5840 | Val ROC-AUC: 0.6311\n",
      "âœ… Final Test | Loss: 0.7902 | Acc: 0.6259 | ROC-AUC: 0.6949\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN(embedding_matrix, True).to(device)\n",
    "trained_model, history = train_and_evaluate(\n",
    "    model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    test_loader,\n",
    "    device=device,\n",
    "    epochs=10,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43985512",
   "metadata": {},
   "source": [
    "# LOOPING THROUGH FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from k_mer_data_loader import prepare_kmer_loaders\n",
    "from initialize_results_df import initialize_results_df\n",
    "from load_sequence_data import load_sequence_data\n",
    "from kmer_2_vec import (\n",
    "    get_kmer_list,\n",
    "    train_word2vec,\n",
    "    build_vocab,\n",
    "    build_embedding_matrix,\n",
    ")\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from kmer_2_vec import SimpleCNN, train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# âœ… Load pretrained Word2Vec\n",
    "w2v_model = Word2Vec.load(\"../Models/kmer2vec_k_6_s_1.model\")\n",
    "\n",
    "# âœ… Build vocab\n",
    "vocab = build_vocab(k=6)\n",
    "\n",
    "# âœ… Build pretrained embeddings dict\n",
    "pretrained_embeddings = {\n",
    "    kmer: w2v_model.wv[kmer] for kmer in w2v_model.wv.index_to_key\n",
    "}\n",
    "\n",
    "# âœ… Build embedding matrix\n",
    "embedding_matrix = build_embedding_matrix(\n",
    "    vocab, pretrained_embeddings, embedding_dim=128\n",
    ")\n",
    "\n",
    "# âœ… Initialize model ONCE â†’ embedding layer frozen\n",
    "model = SimpleCNN(embedding_matrix, freeze_embed=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b60cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_dir = \"../Data\"\n",
    "excel_path = \"../Outputs/50_W2V.xlsx\"\n",
    "\n",
    "# Load dataframes\n",
    "results_df, excel_df = initialize_results_df(data_dir, excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1fa528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadDnd41CtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.3767 | Train Acc: 0.8403 | Val Loss: 0.2815 | Val Acc: 0.8902 | Val ROC-AUC: 0.9549\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.2691 | Train Acc: 0.8896 | Val Loss: 0.2594 | Val Acc: 0.9008 | Val ROC-AUC: 0.9605\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.2461 | Train Acc: 0.9000 | Val Loss: 0.2469 | Val Acc: 0.9053 | Val ROC-AUC: 0.9634\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.2301 | Train Acc: 0.9072 | Val Loss: 0.2536 | Val Acc: 0.9009 | Val ROC-AUC: 0.9640\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2191 | Train Acc: 0.9115 | Val Loss: 0.2346 | Val Acc: 0.9093 | Val ROC-AUC: 0.9660\n",
      "âœ… Final Test | Loss: 0.2312 | Acc: 0.9080 | ROC-AUC: 0.9666\n",
      "âœ… wgEncodeAwgTfbsBroadDnd41CtcfUniPk: train_acc=0.9115, test_acc=0.9080\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadDnd41Ezh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.8017 | Train Acc: 0.6012 | Val Loss: 0.6876 | Val Acc: 0.6082 | Val ROC-AUC: 0.6472\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5629 | Train Acc: 0.7206 | Val Loss: 0.6615 | Val Acc: 0.6157 | Val ROC-AUC: 0.6800\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4644 | Train Acc: 0.7910 | Val Loss: 0.6722 | Val Acc: 0.6175 | Val ROC-AUC: 0.6790\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3790 | Train Acc: 0.8419 | Val Loss: 0.6848 | Val Acc: 0.6157 | Val ROC-AUC: 0.6755\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2920 | Train Acc: 0.8951 | Val Loss: 0.6723 | Val Acc: 0.6362 | Val ROC-AUC: 0.7022\n",
      "âœ… Final Test | Loss: 0.6716 | Acc: 0.6542 | ROC-AUC: 0.7032\n",
      "âœ… wgEncodeAwgTfbsBroadDnd41Ezh239875UniPk: train_acc=0.8951, test_acc=0.6542\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadGm12878CtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.2798 | Train Acc: 0.8870 | Val Loss: 0.2546 | Val Acc: 0.9033 | Val ROC-AUC: 0.9609\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.2487 | Train Acc: 0.9014 | Val Loss: 0.2479 | Val Acc: 0.9060 | Val ROC-AUC: 0.9605\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.2338 | Train Acc: 0.9079 | Val Loss: 0.2410 | Val Acc: 0.9075 | Val ROC-AUC: 0.9624\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.2199 | Train Acc: 0.9139 | Val Loss: 0.2437 | Val Acc: 0.9057 | Val ROC-AUC: 0.9612\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2110 | Train Acc: 0.9165 | Val Loss: 0.2502 | Val Acc: 0.9031 | Val ROC-AUC: 0.9611\n",
      "âœ… Final Test | Loss: 0.2500 | Acc: 0.9020 | ROC-AUC: 0.9605\n",
      "âœ… wgEncodeAwgTfbsBroadGm12878CtcfUniPk: train_acc=0.9165, test_acc=0.9020\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadGm12878Ezh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.7505 | Train Acc: 0.6232 | Val Loss: 0.6342 | Val Acc: 0.6361 | Val ROC-AUC: 0.7037\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5754 | Train Acc: 0.6911 | Val Loss: 0.6189 | Val Acc: 0.6527 | Val ROC-AUC: 0.7138\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4972 | Train Acc: 0.7599 | Val Loss: 0.6122 | Val Acc: 0.6489 | Val ROC-AUC: 0.7203\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4204 | Train Acc: 0.8102 | Val Loss: 0.6294 | Val Acc: 0.6476 | Val ROC-AUC: 0.7140\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3288 | Train Acc: 0.8694 | Val Loss: 0.6366 | Val Acc: 0.6539 | Val ROC-AUC: 0.7170\n",
      "âœ… Final Test | Loss: 0.7104 | Acc: 0.6181 | ROC-AUC: 0.6697\n",
      "âœ… wgEncodeAwgTfbsBroadGm12878Ezh239875UniPk: train_acc=0.8694, test_acc=0.6181\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadH1hescChd1a301218aUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.6762 | Train Acc: 0.6283 | Val Loss: 0.6244 | Val Acc: 0.6497 | Val ROC-AUC: 0.7110\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5696 | Train Acc: 0.7007 | Val Loss: 0.6295 | Val Acc: 0.6523 | Val ROC-AUC: 0.7046\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.5143 | Train Acc: 0.7493 | Val Loss: 0.6375 | Val Acc: 0.6430 | Val ROC-AUC: 0.7020\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4523 | Train Acc: 0.7896 | Val Loss: 0.6488 | Val Acc: 0.6452 | Val ROC-AUC: 0.7045\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3846 | Train Acc: 0.8284 | Val Loss: 0.6822 | Val Acc: 0.6408 | Val ROC-AUC: 0.6963\n",
      "âœ… Final Test | Loss: 0.6580 | Acc: 0.6587 | ROC-AUC: 0.7159\n",
      "âœ… wgEncodeAwgTfbsBroadH1hescChd1a301218aUniPk: train_acc=0.8284, test_acc=0.6587\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadH1hescCtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.2866 | Train Acc: 0.8821 | Val Loss: 0.2419 | Val Acc: 0.9074 | Val ROC-AUC: 0.9659\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.2429 | Train Acc: 0.9033 | Val Loss: 0.2333 | Val Acc: 0.9101 | Val ROC-AUC: 0.9673\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.2293 | Train Acc: 0.9083 | Val Loss: 0.2479 | Val Acc: 0.9032 | Val ROC-AUC: 0.9659\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.2201 | Train Acc: 0.9141 | Val Loss: 0.2387 | Val Acc: 0.9062 | Val ROC-AUC: 0.9680\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2137 | Train Acc: 0.9148 | Val Loss: 0.2357 | Val Acc: 0.9090 | Val ROC-AUC: 0.9676\n",
      "âœ… Final Test | Loss: 0.2324 | Acc: 0.9096 | ROC-AUC: 0.9691\n",
      "âœ… wgEncodeAwgTfbsBroadH1hescCtcfUniPk: train_acc=0.9148, test_acc=0.9096\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadH1hescEzh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.7249 | Train Acc: 0.6246 | Val Loss: 0.6193 | Val Acc: 0.6565 | Val ROC-AUC: 0.7129\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5491 | Train Acc: 0.7098 | Val Loss: 0.6101 | Val Acc: 0.6704 | Val ROC-AUC: 0.7253\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4832 | Train Acc: 0.7665 | Val Loss: 0.6134 | Val Acc: 0.6565 | Val ROC-AUC: 0.7292\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4138 | Train Acc: 0.8126 | Val Loss: 0.6295 | Val Acc: 0.6579 | Val ROC-AUC: 0.7289\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3434 | Train Acc: 0.8541 | Val Loss: 0.6637 | Val Acc: 0.6551 | Val ROC-AUC: 0.7166\n",
      "âœ… Final Test | Loss: 0.6341 | Acc: 0.6705 | ROC-AUC: 0.7390\n",
      "âœ… wgEncodeAwgTfbsBroadH1hescEzh239875UniPk: train_acc=0.8541, test_acc=0.6705\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadH1hescJarid1aab26049UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.6633 | Train Acc: 0.6696 | Val Loss: 0.6047 | Val Acc: 0.6608 | Val ROC-AUC: 0.7403\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.4599 | Train Acc: 0.7853 | Val Loss: 0.5705 | Val Acc: 0.7018 | Val ROC-AUC: 0.7620\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.3589 | Train Acc: 0.8507 | Val Loss: 0.5785 | Val Acc: 0.6959 | Val ROC-AUC: 0.7741\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.2903 | Train Acc: 0.8951 | Val Loss: 0.5865 | Val Acc: 0.7037 | Val ROC-AUC: 0.7732\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2142 | Train Acc: 0.9297 | Val Loss: 0.5986 | Val Acc: 0.7193 | Val ROC-AUC: 0.7762\n",
      "âœ… Final Test | Loss: 0.5733 | Acc: 0.7020 | ROC-AUC: 0.7795\n",
      "âœ… wgEncodeAwgTfbsBroadH1hescJarid1aab26049UniPk: train_acc=0.9297, test_acc=0.7020\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadH1hescRbbp5a300109aUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.6250 | Train Acc: 0.6675 | Val Loss: 0.5737 | Val Acc: 0.7040 | Val ROC-AUC: 0.7760\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5474 | Train Acc: 0.7174 | Val Loss: 0.5751 | Val Acc: 0.6922 | Val ROC-AUC: 0.7717\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.5109 | Train Acc: 0.7466 | Val Loss: 0.5667 | Val Acc: 0.7126 | Val ROC-AUC: 0.7775\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4667 | Train Acc: 0.7759 | Val Loss: 0.5694 | Val Acc: 0.6979 | Val ROC-AUC: 0.7756\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.4383 | Train Acc: 0.7945 | Val Loss: 0.5699 | Val Acc: 0.7040 | Val ROC-AUC: 0.7755\n",
      "âœ… Final Test | Loss: 0.5836 | Acc: 0.6952 | ROC-AUC: 0.7626\n",
      "âœ… wgEncodeAwgTfbsBroadH1hescRbbp5a300109aUniPk: train_acc=0.7945, test_acc=0.6952\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHelas3CtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.3157 | Train Acc: 0.8679 | Val Loss: 0.2910 | Val Acc: 0.8823 | Val ROC-AUC: 0.9480\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.2725 | Train Acc: 0.8900 | Val Loss: 0.2788 | Val Acc: 0.8877 | Val ROC-AUC: 0.9493\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.2532 | Train Acc: 0.8983 | Val Loss: 0.2944 | Val Acc: 0.8804 | Val ROC-AUC: 0.9501\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.2418 | Train Acc: 0.9015 | Val Loss: 0.2805 | Val Acc: 0.8862 | Val ROC-AUC: 0.9495\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2291 | Train Acc: 0.9074 | Val Loss: 0.2835 | Val Acc: 0.8828 | Val ROC-AUC: 0.9498\n",
      "âœ… Final Test | Loss: 0.2782 | Acc: 0.8888 | ROC-AUC: 0.9519\n",
      "âœ… wgEncodeAwgTfbsBroadHelas3CtcfUniPk: train_acc=0.9074, test_acc=0.8888\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHelas3Ezh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.7880 | Train Acc: 0.6129 | Val Loss: 0.6201 | Val Acc: 0.6561 | Val ROC-AUC: 0.7256\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5479 | Train Acc: 0.7178 | Val Loss: 0.6106 | Val Acc: 0.6667 | Val ROC-AUC: 0.7334\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4562 | Train Acc: 0.7840 | Val Loss: 0.6221 | Val Acc: 0.6490 | Val ROC-AUC: 0.7314\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3683 | Train Acc: 0.8470 | Val Loss: 0.6407 | Val Acc: 0.6473 | Val ROC-AUC: 0.7241\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2854 | Train Acc: 0.9008 | Val Loss: 0.6749 | Val Acc: 0.6384 | Val ROC-AUC: 0.7188\n",
      "âœ… Final Test | Loss: 0.6631 | Acc: 0.6423 | ROC-AUC: 0.7131\n",
      "âœ… wgEncodeAwgTfbsBroadHelas3Ezh239875UniPk: train_acc=0.9008, test_acc=0.6423\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHelas3Pol2bUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.7052 | Train Acc: 0.6262 | Val Loss: 0.6247 | Val Acc: 0.6464 | Val ROC-AUC: 0.7117\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5357 | Train Acc: 0.7257 | Val Loss: 0.6186 | Val Acc: 0.6464 | Val ROC-AUC: 0.7203\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4425 | Train Acc: 0.8099 | Val Loss: 0.6218 | Val Acc: 0.6559 | Val ROC-AUC: 0.7267\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3625 | Train Acc: 0.8458 | Val Loss: 0.6605 | Val Acc: 0.6391 | Val ROC-AUC: 0.7127\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2765 | Train Acc: 0.8916 | Val Loss: 0.7029 | Val Acc: 0.6485 | Val ROC-AUC: 0.7099\n",
      "âœ… Final Test | Loss: 0.6587 | Acc: 0.6603 | ROC-AUC: 0.7286\n",
      "âœ… wgEncodeAwgTfbsBroadHelas3Pol2bUniPk: train_acc=0.8916, test_acc=0.6603\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHepg2CtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.2298 | Train Acc: 0.9109 | Val Loss: 0.2013 | Val Acc: 0.9280 | Val ROC-AUC: 0.9772\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.1880 | Train Acc: 0.9283 | Val Loss: 0.1918 | Val Acc: 0.9311 | Val ROC-AUC: 0.9781\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.1734 | Train Acc: 0.9332 | Val Loss: 0.1926 | Val Acc: 0.9282 | Val ROC-AUC: 0.9770\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.1639 | Train Acc: 0.9371 | Val Loss: 0.2037 | Val Acc: 0.9246 | Val ROC-AUC: 0.9760\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.1524 | Train Acc: 0.9417 | Val Loss: 0.1994 | Val Acc: 0.9242 | Val ROC-AUC: 0.9755\n",
      "âœ… Final Test | Loss: 0.2032 | Acc: 0.9256 | ROC-AUC: 0.9741\n",
      "âœ… wgEncodeAwgTfbsBroadHepg2CtcfUniPk: train_acc=0.9417, test_acc=0.9256\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHepg2Ezh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.8461 | Train Acc: 0.6122 | Val Loss: 0.6773 | Val Acc: 0.6246 | Val ROC-AUC: 0.6706\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5644 | Train Acc: 0.7147 | Val Loss: 0.6499 | Val Acc: 0.6332 | Val ROC-AUC: 0.6867\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4818 | Train Acc: 0.7775 | Val Loss: 0.6432 | Val Acc: 0.6380 | Val ROC-AUC: 0.6987\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4038 | Train Acc: 0.8181 | Val Loss: 0.6484 | Val Acc: 0.6552 | Val ROC-AUC: 0.7065\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3192 | Train Acc: 0.8725 | Val Loss: 0.6742 | Val Acc: 0.6437 | Val ROC-AUC: 0.7032\n",
      "âœ… Final Test | Loss: 0.6916 | Acc: 0.6440 | ROC-AUC: 0.6992\n",
      "âœ… wgEncodeAwgTfbsBroadHepg2Ezh239875UniPk: train_acc=0.8725, test_acc=0.6440\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHmecCtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.2126 | Train Acc: 0.9185 | Val Loss: 0.1864 | Val Acc: 0.9329 | Val ROC-AUC: 0.9791\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.1745 | Train Acc: 0.9343 | Val Loss: 0.1834 | Val Acc: 0.9343 | Val ROC-AUC: 0.9790\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.1583 | Train Acc: 0.9401 | Val Loss: 0.1834 | Val Acc: 0.9317 | Val ROC-AUC: 0.9783\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.1451 | Train Acc: 0.9453 | Val Loss: 0.1880 | Val Acc: 0.9286 | Val ROC-AUC: 0.9773\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.1342 | Train Acc: 0.9485 | Val Loss: 0.1946 | Val Acc: 0.9268 | Val ROC-AUC: 0.9781\n",
      "âœ… Final Test | Loss: 0.1908 | Acc: 0.9285 | ROC-AUC: 0.9783\n",
      "âœ… wgEncodeAwgTfbsBroadHmecCtcfUniPk: train_acc=0.9485, test_acc=0.9285\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHmecEzh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.8474 | Train Acc: 0.5813 | Val Loss: 0.6738 | Val Acc: 0.6273 | Val ROC-AUC: 0.6588\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.6009 | Train Acc: 0.6790 | Val Loss: 0.6625 | Val Acc: 0.6294 | Val ROC-AUC: 0.6738\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.5312 | Train Acc: 0.7412 | Val Loss: 0.6536 | Val Acc: 0.6273 | Val ROC-AUC: 0.6789\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4613 | Train Acc: 0.7862 | Val Loss: 0.6667 | Val Acc: 0.6431 | Val ROC-AUC: 0.6866\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3991 | Train Acc: 0.8221 | Val Loss: 0.6839 | Val Acc: 0.6280 | Val ROC-AUC: 0.6818\n",
      "âœ… Final Test | Loss: 0.6788 | Acc: 0.6393 | ROC-AUC: 0.6889\n",
      "âœ… wgEncodeAwgTfbsBroadHmecEzh239875UniPk: train_acc=0.8221, test_acc=0.6393\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHsmmCtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.2397 | Train Acc: 0.9041 | Val Loss: 0.1934 | Val Acc: 0.9275 | Val ROC-AUC: 0.9780\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.1994 | Train Acc: 0.9231 | Val Loss: 0.1979 | Val Acc: 0.9273 | Val ROC-AUC: 0.9777\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.1852 | Train Acc: 0.9283 | Val Loss: 0.1935 | Val Acc: 0.9256 | Val ROC-AUC: 0.9772\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.1718 | Train Acc: 0.9325 | Val Loss: 0.1953 | Val Acc: 0.9256 | Val ROC-AUC: 0.9769\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.1679 | Train Acc: 0.9345 | Val Loss: 0.1999 | Val Acc: 0.9235 | Val ROC-AUC: 0.9757\n",
      "âœ… Final Test | Loss: 0.2103 | Acc: 0.9194 | ROC-AUC: 0.9730\n",
      "âœ… wgEncodeAwgTfbsBroadHsmmCtcfUniPk: train_acc=0.9345, test_acc=0.9194\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHsmmEzh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.9447 | Train Acc: 0.5819 | Val Loss: 0.6909 | Val Acc: 0.6410 | Val ROC-AUC: 0.6792\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.6035 | Train Acc: 0.6880 | Val Loss: 0.6607 | Val Acc: 0.6369 | Val ROC-AUC: 0.6876\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4972 | Train Acc: 0.7656 | Val Loss: 0.6439 | Val Acc: 0.6329 | Val ROC-AUC: 0.6998\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4169 | Train Acc: 0.8189 | Val Loss: 0.6476 | Val Acc: 0.6592 | Val ROC-AUC: 0.7044\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3310 | Train Acc: 0.8752 | Val Loss: 0.6620 | Val Acc: 0.6511 | Val ROC-AUC: 0.7008\n",
      "âœ… Final Test | Loss: 0.6923 | Acc: 0.6477 | ROC-AUC: 0.6835\n",
      "âœ… wgEncodeAwgTfbsBroadHsmmEzh239875UniPk: train_acc=0.8752, test_acc=0.6477\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHsmmtCtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.2422 | Train Acc: 0.9058 | Val Loss: 0.2340 | Val Acc: 0.9125 | Val ROC-AUC: 0.9695\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.2107 | Train Acc: 0.9180 | Val Loss: 0.2225 | Val Acc: 0.9150 | Val ROC-AUC: 0.9686\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.1966 | Train Acc: 0.9236 | Val Loss: 0.2269 | Val Acc: 0.9119 | Val ROC-AUC: 0.9677\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.1874 | Train Acc: 0.9278 | Val Loss: 0.2257 | Val Acc: 0.9129 | Val ROC-AUC: 0.9675\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.1774 | Train Acc: 0.9327 | Val Loss: 0.2293 | Val Acc: 0.9125 | Val ROC-AUC: 0.9673\n",
      "âœ… Final Test | Loss: 0.2253 | Acc: 0.9161 | ROC-AUC: 0.9685\n",
      "âœ… wgEncodeAwgTfbsBroadHsmmtCtcfUniPk: train_acc=0.9327, test_acc=0.9161\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHsmmtEzh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.8014 | Train Acc: 0.6024 | Val Loss: 0.6230 | Val Acc: 0.6531 | Val ROC-AUC: 0.7185\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5504 | Train Acc: 0.7241 | Val Loss: 0.5943 | Val Acc: 0.6682 | Val ROC-AUC: 0.7441\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4872 | Train Acc: 0.7614 | Val Loss: 0.5919 | Val Acc: 0.6787 | Val ROC-AUC: 0.7483\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4000 | Train Acc: 0.8283 | Val Loss: 0.5979 | Val Acc: 0.6810 | Val ROC-AUC: 0.7492\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3215 | Train Acc: 0.8725 | Val Loss: 0.6385 | Val Acc: 0.6694 | Val ROC-AUC: 0.7359\n",
      "âœ… Final Test | Loss: 0.6792 | Acc: 0.6453 | ROC-AUC: 0.7134\n",
      "âœ… wgEncodeAwgTfbsBroadHsmmtEzh239875UniPk: train_acc=0.8725, test_acc=0.6453\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHuvecCtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.2246 | Train Acc: 0.9121 | Val Loss: 0.1908 | Val Acc: 0.9340 | Val ROC-AUC: 0.9770\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.1878 | Train Acc: 0.9294 | Val Loss: 0.1969 | Val Acc: 0.9293 | Val ROC-AUC: 0.9750\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.1724 | Train Acc: 0.9351 | Val Loss: 0.1903 | Val Acc: 0.9306 | Val ROC-AUC: 0.9758\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.1582 | Train Acc: 0.9389 | Val Loss: 0.2037 | Val Acc: 0.9251 | Val ROC-AUC: 0.9741\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.1499 | Train Acc: 0.9429 | Val Loss: 0.2079 | Val Acc: 0.9210 | Val ROC-AUC: 0.9734\n",
      "âœ… Final Test | Loss: 0.1992 | Acc: 0.9263 | ROC-AUC: 0.9748\n",
      "âœ… wgEncodeAwgTfbsBroadHuvecCtcfUniPk: train_acc=0.9429, test_acc=0.9263\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHuvecEzh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.7618 | Train Acc: 0.6289 | Val Loss: 0.6043 | Val Acc: 0.6773 | Val ROC-AUC: 0.7387\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5517 | Train Acc: 0.7195 | Val Loss: 0.5891 | Val Acc: 0.6957 | Val ROC-AUC: 0.7545\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4642 | Train Acc: 0.7812 | Val Loss: 0.5812 | Val Acc: 0.6965 | Val ROC-AUC: 0.7614\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3960 | Train Acc: 0.8216 | Val Loss: 0.5796 | Val Acc: 0.7083 | Val ROC-AUC: 0.7697\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3186 | Train Acc: 0.8661 | Val Loss: 0.6017 | Val Acc: 0.6942 | Val ROC-AUC: 0.7668\n",
      "âœ… Final Test | Loss: 0.6259 | Acc: 0.6843 | ROC-AUC: 0.7538\n",
      "âœ… wgEncodeAwgTfbsBroadHuvecEzh239875UniPk: train_acc=0.8661, test_acc=0.6843\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadHuvecPol2bUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.6634 | Train Acc: 0.6538 | Val Loss: 0.5638 | Val Acc: 0.7065 | Val ROC-AUC: 0.7768\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5122 | Train Acc: 0.7455 | Val Loss: 0.5576 | Val Acc: 0.7173 | Val ROC-AUC: 0.7838\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4362 | Train Acc: 0.8027 | Val Loss: 0.5728 | Val Acc: 0.7065 | Val ROC-AUC: 0.7798\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3624 | Train Acc: 0.8430 | Val Loss: 0.5880 | Val Acc: 0.7035 | Val ROC-AUC: 0.7725\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2943 | Train Acc: 0.8786 | Val Loss: 0.6163 | Val Acc: 0.6927 | Val ROC-AUC: 0.7640\n",
      "âœ… Final Test | Loss: 0.6502 | Acc: 0.6737 | ROC-AUC: 0.7432\n",
      "âœ… wgEncodeAwgTfbsBroadHuvecPol2bUniPk: train_acc=0.8786, test_acc=0.6737\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadK562Chd1a301218aUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.6604 | Train Acc: 0.6571 | Val Loss: 0.6053 | Val Acc: 0.6764 | Val ROC-AUC: 0.7402\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5446 | Train Acc: 0.7195 | Val Loss: 0.5985 | Val Acc: 0.6859 | Val ROC-AUC: 0.7455\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4839 | Train Acc: 0.7666 | Val Loss: 0.6055 | Val Acc: 0.6828 | Val ROC-AUC: 0.7420\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4335 | Train Acc: 0.8005 | Val Loss: 0.6157 | Val Acc: 0.6740 | Val ROC-AUC: 0.7446\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3709 | Train Acc: 0.8348 | Val Loss: 0.6530 | Val Acc: 0.6777 | Val ROC-AUC: 0.7356\n",
      "âœ… Final Test | Loss: 0.6602 | Acc: 0.6663 | ROC-AUC: 0.7278\n",
      "âœ… wgEncodeAwgTfbsBroadK562Chd1a301218aUniPk: train_acc=0.8348, test_acc=0.6663\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadK562CtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.3403 | Train Acc: 0.8553 | Val Loss: 0.2950 | Val Acc: 0.8820 | Val ROC-AUC: 0.9435\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.2851 | Train Acc: 0.8839 | Val Loss: 0.2941 | Val Acc: 0.8828 | Val ROC-AUC: 0.9431\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.2660 | Train Acc: 0.8906 | Val Loss: 0.2904 | Val Acc: 0.8848 | Val ROC-AUC: 0.9432\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.2529 | Train Acc: 0.8976 | Val Loss: 0.2911 | Val Acc: 0.8833 | Val ROC-AUC: 0.9429\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2418 | Train Acc: 0.9010 | Val Loss: 0.2928 | Val Acc: 0.8805 | Val ROC-AUC: 0.9421\n",
      "âœ… Final Test | Loss: 0.2957 | Acc: 0.8775 | ROC-AUC: 0.9426\n",
      "âœ… wgEncodeAwgTfbsBroadK562CtcfUniPk: train_acc=0.9010, test_acc=0.8775\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadK562Ezh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.7361 | Train Acc: 0.6227 | Val Loss: 0.7006 | Val Acc: 0.5978 | Val ROC-AUC: 0.6661\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5224 | Train Acc: 0.7373 | Val Loss: 0.6570 | Val Acc: 0.6127 | Val ROC-AUC: 0.6785\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4353 | Train Acc: 0.8020 | Val Loss: 0.6785 | Val Acc: 0.5847 | Val ROC-AUC: 0.6625\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3441 | Train Acc: 0.8654 | Val Loss: 0.6924 | Val Acc: 0.6089 | Val ROC-AUC: 0.6692\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2753 | Train Acc: 0.8985 | Val Loss: 0.7313 | Val Acc: 0.6108 | Val ROC-AUC: 0.6651\n",
      "âœ… Final Test | Loss: 0.6704 | Acc: 0.6696 | ROC-AUC: 0.7172\n",
      "âœ… wgEncodeAwgTfbsBroadK562Ezh239875UniPk: train_acc=0.8985, test_acc=0.6696\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadK562Hdac1sc6298UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.6356 | Train Acc: 0.6565 | Val Loss: 0.5939 | Val Acc: 0.6797 | Val ROC-AUC: 0.7513\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5479 | Train Acc: 0.7209 | Val Loss: 0.5943 | Val Acc: 0.6816 | Val ROC-AUC: 0.7581\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4916 | Train Acc: 0.7592 | Val Loss: 0.5881 | Val Acc: 0.6894 | Val ROC-AUC: 0.7598\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4421 | Train Acc: 0.7900 | Val Loss: 0.5977 | Val Acc: 0.6939 | Val ROC-AUC: 0.7566\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3937 | Train Acc: 0.8231 | Val Loss: 0.6200 | Val Acc: 0.6819 | Val ROC-AUC: 0.7501\n",
      "âœ… Final Test | Loss: 0.6332 | Acc: 0.6788 | ROC-AUC: 0.7442\n",
      "âœ… wgEncodeAwgTfbsBroadK562Hdac1sc6298UniPk: train_acc=0.8231, test_acc=0.6788\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadK562Hdac2a300705aUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.6101 | Train Acc: 0.6898 | Val Loss: 0.5697 | Val Acc: 0.6975 | Val ROC-AUC: 0.7765\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.4908 | Train Acc: 0.7594 | Val Loss: 0.5681 | Val Acc: 0.7023 | Val ROC-AUC: 0.7784\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4032 | Train Acc: 0.8156 | Val Loss: 0.5829 | Val Acc: 0.6897 | Val ROC-AUC: 0.7669\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3262 | Train Acc: 0.8613 | Val Loss: 0.6100 | Val Acc: 0.6832 | Val ROC-AUC: 0.7586\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2675 | Train Acc: 0.8899 | Val Loss: 0.6714 | Val Acc: 0.6814 | Val ROC-AUC: 0.7453\n",
      "âœ… Final Test | Loss: 0.6243 | Acc: 0.7109 | ROC-AUC: 0.7820\n",
      "âœ… wgEncodeAwgTfbsBroadK562Hdac2a300705aUniPk: train_acc=0.8899, test_acc=0.7109\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadK562Hdac6a301341aUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.7293 | Train Acc: 0.6643 | Val Loss: 0.6587 | Val Acc: 0.6912 | Val ROC-AUC: 0.7592\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.4614 | Train Acc: 0.7847 | Val Loss: 0.6239 | Val Acc: 0.6856 | Val ROC-AUC: 0.7536\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.3256 | Train Acc: 0.8654 | Val Loss: 0.6315 | Val Acc: 0.6827 | Val ROC-AUC: 0.7542\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.2824 | Train Acc: 0.8959 | Val Loss: 0.6206 | Val Acc: 0.6856 | Val ROC-AUC: 0.7564\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2135 | Train Acc: 0.9313 | Val Loss: 0.6306 | Val Acc: 0.6997 | Val ROC-AUC: 0.7637\n",
      "âœ… Final Test | Loss: 0.6592 | Acc: 0.6607 | ROC-AUC: 0.7380\n",
      "âœ… wgEncodeAwgTfbsBroadK562Hdac6a301341aUniPk: train_acc=0.9313, test_acc=0.6607\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadK562P300UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.7550 | Train Acc: 0.6458 | Val Loss: 0.5903 | Val Acc: 0.6846 | Val ROC-AUC: 0.7490\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5015 | Train Acc: 0.7517 | Val Loss: 0.5860 | Val Acc: 0.6833 | Val ROC-AUC: 0.7546\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4113 | Train Acc: 0.8130 | Val Loss: 0.5836 | Val Acc: 0.6987 | Val ROC-AUC: 0.7661\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3116 | Train Acc: 0.8749 | Val Loss: 0.6173 | Val Acc: 0.6859 | Val ROC-AUC: 0.7501\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2307 | Train Acc: 0.9140 | Val Loss: 0.6377 | Val Acc: 0.6769 | Val ROC-AUC: 0.7506\n",
      "âœ… Final Test | Loss: 0.6574 | Acc: 0.6683 | ROC-AUC: 0.7496\n",
      "âœ… wgEncodeAwgTfbsBroadK562P300UniPk: train_acc=0.9140, test_acc=0.6683\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadK562Phf8a301772aUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.6154 | Train Acc: 0.6764 | Val Loss: 0.5587 | Val Acc: 0.7141 | Val ROC-AUC: 0.7894\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5282 | Train Acc: 0.7347 | Val Loss: 0.5473 | Val Acc: 0.7227 | Val ROC-AUC: 0.7957\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4886 | Train Acc: 0.7602 | Val Loss: 0.5553 | Val Acc: 0.7163 | Val ROC-AUC: 0.7894\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4533 | Train Acc: 0.7861 | Val Loss: 0.5561 | Val Acc: 0.7127 | Val ROC-AUC: 0.7887\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.4184 | Train Acc: 0.8059 | Val Loss: 0.5677 | Val Acc: 0.7192 | Val ROC-AUC: 0.7844\n",
      "âœ… Final Test | Loss: 0.5692 | Acc: 0.7123 | ROC-AUC: 0.7827\n",
      "âœ… wgEncodeAwgTfbsBroadK562Phf8a301772aUniPk: train_acc=0.8059, test_acc=0.7123\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadK562Plu1UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.5686 | Train Acc: 0.7030 | Val Loss: 0.5343 | Val Acc: 0.7294 | Val ROC-AUC: 0.8091\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.4998 | Train Acc: 0.7512 | Val Loss: 0.5312 | Val Acc: 0.7240 | Val ROC-AUC: 0.8088\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4495 | Train Acc: 0.7881 | Val Loss: 0.5383 | Val Acc: 0.7143 | Val ROC-AUC: 0.8007\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4107 | Train Acc: 0.8102 | Val Loss: 0.5464 | Val Acc: 0.7134 | Val ROC-AUC: 0.7962\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3686 | Train Acc: 0.8327 | Val Loss: 0.5758 | Val Acc: 0.7140 | Val ROC-AUC: 0.7876\n",
      "âœ… Final Test | Loss: 0.5653 | Acc: 0.7223 | ROC-AUC: 0.7952\n",
      "âœ… wgEncodeAwgTfbsBroadK562Plu1UniPk: train_acc=0.8327, test_acc=0.7223\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadK562Pol2bUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.5855 | Train Acc: 0.7021 | Val Loss: 0.5444 | Val Acc: 0.7272 | Val ROC-AUC: 0.8019\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.4889 | Train Acc: 0.7623 | Val Loss: 0.5429 | Val Acc: 0.7218 | Val ROC-AUC: 0.7979\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4269 | Train Acc: 0.7984 | Val Loss: 0.5502 | Val Acc: 0.7105 | Val ROC-AUC: 0.7922\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3679 | Train Acc: 0.8350 | Val Loss: 0.5695 | Val Acc: 0.7130 | Val ROC-AUC: 0.7911\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3242 | Train Acc: 0.8609 | Val Loss: 0.5954 | Val Acc: 0.7119 | Val ROC-AUC: 0.7807\n",
      "âœ… Final Test | Loss: 0.5767 | Acc: 0.7157 | ROC-AUC: 0.7935\n",
      "âœ… wgEncodeAwgTfbsBroadK562Pol2bUniPk: train_acc=0.8609, test_acc=0.7157\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadK562Rbbp5a300109aUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.5928 | Train Acc: 0.6973 | Val Loss: 0.5444 | Val Acc: 0.7232 | Val ROC-AUC: 0.7981\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5017 | Train Acc: 0.7539 | Val Loss: 0.5365 | Val Acc: 0.7308 | Val ROC-AUC: 0.8047\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4510 | Train Acc: 0.7853 | Val Loss: 0.5425 | Val Acc: 0.7278 | Val ROC-AUC: 0.8001\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4063 | Train Acc: 0.8126 | Val Loss: 0.5667 | Val Acc: 0.7141 | Val ROC-AUC: 0.7907\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3652 | Train Acc: 0.8353 | Val Loss: 0.5805 | Val Acc: 0.7091 | Val ROC-AUC: 0.7832\n",
      "âœ… Final Test | Loss: 0.5858 | Acc: 0.7038 | ROC-AUC: 0.7798\n",
      "âœ… wgEncodeAwgTfbsBroadK562Rbbp5a300109aUniPk: train_acc=0.8353, test_acc=0.7038\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadK562Sap3039731UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.5854 | Train Acc: 0.7011 | Val Loss: 0.5542 | Val Acc: 0.7124 | Val ROC-AUC: 0.7905\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.4904 | Train Acc: 0.7591 | Val Loss: 0.5524 | Val Acc: 0.7218 | Val ROC-AUC: 0.7918\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4238 | Train Acc: 0.8041 | Val Loss: 0.5733 | Val Acc: 0.7108 | Val ROC-AUC: 0.7868\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3672 | Train Acc: 0.8375 | Val Loss: 0.5890 | Val Acc: 0.7082 | Val ROC-AUC: 0.7783\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3105 | Train Acc: 0.8650 | Val Loss: 0.5952 | Val Acc: 0.7089 | Val ROC-AUC: 0.7835\n",
      "âœ… Final Test | Loss: 0.5658 | Acc: 0.7216 | ROC-AUC: 0.8015\n",
      "âœ… wgEncodeAwgTfbsBroadK562Sap3039731UniPk: train_acc=0.8650, test_acc=0.7216\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadNhaCtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.3509 | Train Acc: 0.8467 | Val Loss: 0.2485 | Val Acc: 0.9025 | Val ROC-AUC: 0.9614\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.2325 | Train Acc: 0.9088 | Val Loss: 0.2335 | Val Acc: 0.9102 | Val ROC-AUC: 0.9657\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.2027 | Train Acc: 0.9218 | Val Loss: 0.2262 | Val Acc: 0.9147 | Val ROC-AUC: 0.9692\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.1848 | Train Acc: 0.9294 | Val Loss: 0.2308 | Val Acc: 0.9102 | Val ROC-AUC: 0.9679\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.1639 | Train Acc: 0.9371 | Val Loss: 0.2265 | Val Acc: 0.9154 | Val ROC-AUC: 0.9679\n",
      "âœ… Final Test | Loss: 0.2090 | Acc: 0.9195 | ROC-AUC: 0.9722\n",
      "âœ… wgEncodeAwgTfbsBroadNhaCtcfUniPk: train_acc=0.9371, test_acc=0.9195\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadNhaEzh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.7192 | Train Acc: 0.6454 | Val Loss: 0.5936 | Val Acc: 0.6836 | Val ROC-AUC: 0.7486\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5419 | Train Acc: 0.7269 | Val Loss: 0.5802 | Val Acc: 0.6991 | Val ROC-AUC: 0.7642\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4636 | Train Acc: 0.7836 | Val Loss: 0.5797 | Val Acc: 0.6896 | Val ROC-AUC: 0.7647\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3934 | Train Acc: 0.8273 | Val Loss: 0.5946 | Val Acc: 0.6848 | Val ROC-AUC: 0.7643\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3163 | Train Acc: 0.8652 | Val Loss: 0.6166 | Val Acc: 0.6908 | Val ROC-AUC: 0.7603\n",
      "âœ… Final Test | Loss: 0.6378 | Acc: 0.6883 | ROC-AUC: 0.7616\n",
      "âœ… wgEncodeAwgTfbsBroadNhaEzh239875UniPk: train_acc=0.8652, test_acc=0.6883\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadNhdfadCtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.2527 | Train Acc: 0.8989 | Val Loss: 0.2132 | Val Acc: 0.9201 | Val ROC-AUC: 0.9730\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.2097 | Train Acc: 0.9182 | Val Loss: 0.2087 | Val Acc: 0.9201 | Val ROC-AUC: 0.9732\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.1925 | Train Acc: 0.9248 | Val Loss: 0.2057 | Val Acc: 0.9235 | Val ROC-AUC: 0.9743\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.1802 | Train Acc: 0.9309 | Val Loss: 0.2094 | Val Acc: 0.9215 | Val ROC-AUC: 0.9731\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.1730 | Train Acc: 0.9332 | Val Loss: 0.2139 | Val Acc: 0.9185 | Val ROC-AUC: 0.9724\n",
      "âœ… Final Test | Loss: 0.2140 | Acc: 0.9161 | ROC-AUC: 0.9729\n",
      "âœ… wgEncodeAwgTfbsBroadNhdfadCtcfUniPk: train_acc=0.9332, test_acc=0.9161\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadNhdfadEzh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.7266 | Train Acc: 0.6490 | Val Loss: 0.5830 | Val Acc: 0.6796 | Val ROC-AUC: 0.7597\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5214 | Train Acc: 0.7378 | Val Loss: 0.5671 | Val Acc: 0.6897 | Val ROC-AUC: 0.7759\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4507 | Train Acc: 0.7913 | Val Loss: 0.5602 | Val Acc: 0.6998 | Val ROC-AUC: 0.7852\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3714 | Train Acc: 0.8407 | Val Loss: 0.5752 | Val Acc: 0.7064 | Val ROC-AUC: 0.7928\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3166 | Train Acc: 0.8661 | Val Loss: 0.5887 | Val Acc: 0.7135 | Val ROC-AUC: 0.7849\n",
      "âœ… Final Test | Loss: 0.6097 | Acc: 0.7048 | ROC-AUC: 0.7734\n",
      "âœ… wgEncodeAwgTfbsBroadNhdfadEzh239875UniPk: train_acc=0.8661, test_acc=0.7048\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadNhekCtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.2627 | Train Acc: 0.8945 | Val Loss: 0.2347 | Val Acc: 0.9112 | Val ROC-AUC: 0.9659\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.2215 | Train Acc: 0.9114 | Val Loss: 0.2383 | Val Acc: 0.9074 | Val ROC-AUC: 0.9637\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.2072 | Train Acc: 0.9176 | Val Loss: 0.2362 | Val Acc: 0.9085 | Val ROC-AUC: 0.9649\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.1913 | Train Acc: 0.9245 | Val Loss: 0.2376 | Val Acc: 0.9087 | Val ROC-AUC: 0.9635\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.1839 | Train Acc: 0.9273 | Val Loss: 0.2392 | Val Acc: 0.9079 | Val ROC-AUC: 0.9633\n",
      "âœ… Final Test | Loss: 0.2306 | Acc: 0.9100 | ROC-AUC: 0.9660\n",
      "âœ… wgEncodeAwgTfbsBroadNhekCtcfUniPk: train_acc=0.9273, test_acc=0.9100\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadNhekEzh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.7068 | Train Acc: 0.6364 | Val Loss: 0.5995 | Val Acc: 0.6829 | Val ROC-AUC: 0.7428\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5495 | Train Acc: 0.7159 | Val Loss: 0.5969 | Val Acc: 0.6787 | Val ROC-AUC: 0.7470\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4847 | Train Acc: 0.7668 | Val Loss: 0.5989 | Val Acc: 0.6829 | Val ROC-AUC: 0.7517\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4144 | Train Acc: 0.8124 | Val Loss: 0.6172 | Val Acc: 0.6791 | Val ROC-AUC: 0.7445\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3597 | Train Acc: 0.8440 | Val Loss: 0.6401 | Val Acc: 0.6804 | Val ROC-AUC: 0.7418\n",
      "âœ… Final Test | Loss: 0.6290 | Acc: 0.6768 | ROC-AUC: 0.7472\n",
      "âœ… wgEncodeAwgTfbsBroadNhekEzh239875UniPk: train_acc=0.8440, test_acc=0.6768\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadNhekPol2bUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.6787 | Train Acc: 0.6420 | Val Loss: 0.6060 | Val Acc: 0.6742 | Val ROC-AUC: 0.7323\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5329 | Train Acc: 0.7276 | Val Loss: 0.6022 | Val Acc: 0.6781 | Val ROC-AUC: 0.7415\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4657 | Train Acc: 0.7825 | Val Loss: 0.6105 | Val Acc: 0.6775 | Val ROC-AUC: 0.7383\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3921 | Train Acc: 0.8224 | Val Loss: 0.6245 | Val Acc: 0.6704 | Val ROC-AUC: 0.7386\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3269 | Train Acc: 0.8624 | Val Loss: 0.6646 | Val Acc: 0.6554 | Val ROC-AUC: 0.7244\n",
      "âœ… Final Test | Loss: 0.6444 | Acc: 0.6768 | ROC-AUC: 0.7397\n",
      "âœ… wgEncodeAwgTfbsBroadNhekPol2bUniPk: train_acc=0.8624, test_acc=0.6768\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadNhlfCtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.2691 | Train Acc: 0.8888 | Val Loss: 0.2140 | Val Acc: 0.9202 | Val ROC-AUC: 0.9715\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.2120 | Train Acc: 0.9185 | Val Loss: 0.2138 | Val Acc: 0.9199 | Val ROC-AUC: 0.9715\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.1919 | Train Acc: 0.9254 | Val Loss: 0.2114 | Val Acc: 0.9212 | Val ROC-AUC: 0.9711\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.1784 | Train Acc: 0.9304 | Val Loss: 0.2208 | Val Acc: 0.9131 | Val ROC-AUC: 0.9717\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.1638 | Train Acc: 0.9362 | Val Loss: 0.2178 | Val Acc: 0.9177 | Val ROC-AUC: 0.9699\n",
      "âœ… Final Test | Loss: 0.2198 | Acc: 0.9156 | ROC-AUC: 0.9695\n",
      "âœ… wgEncodeAwgTfbsBroadNhlfCtcfUniPk: train_acc=0.9362, test_acc=0.9156\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadNhlfEzh239875UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.6922 | Train Acc: 0.6446 | Val Loss: 0.6078 | Val Acc: 0.6574 | Val ROC-AUC: 0.7272\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.5432 | Train Acc: 0.7245 | Val Loss: 0.5998 | Val Acc: 0.6688 | Val ROC-AUC: 0.7382\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.4712 | Train Acc: 0.7753 | Val Loss: 0.6038 | Val Acc: 0.6756 | Val ROC-AUC: 0.7436\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.4052 | Train Acc: 0.8145 | Val Loss: 0.6212 | Val Acc: 0.6720 | Val ROC-AUC: 0.7375\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.3402 | Train Acc: 0.8539 | Val Loss: 0.6487 | Val Acc: 0.6738 | Val ROC-AUC: 0.7344\n",
      "âœ… Final Test | Loss: 0.6441 | Acc: 0.6766 | ROC-AUC: 0.7392\n",
      "âœ… wgEncodeAwgTfbsBroadNhlfEzh239875UniPk: train_acc=0.8539, test_acc=0.6766\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsBroadOsteoblCtcfUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.2901 | Train Acc: 0.8831 | Val Loss: 0.2608 | Val Acc: 0.8992 | Val ROC-AUC: 0.9563\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.2516 | Train Acc: 0.9006 | Val Loss: 0.2581 | Val Acc: 0.8990 | Val ROC-AUC: 0.9570\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.2362 | Train Acc: 0.9066 | Val Loss: 0.2615 | Val Acc: 0.8982 | Val ROC-AUC: 0.9550\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.2226 | Train Acc: 0.9124 | Val Loss: 0.2580 | Val Acc: 0.8972 | Val ROC-AUC: 0.9564\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2149 | Train Acc: 0.9151 | Val Loss: 0.2583 | Val Acc: 0.8989 | Val ROC-AUC: 0.9555\n",
      "âœ… Final Test | Loss: 0.2635 | Acc: 0.8954 | ROC-AUC: 0.9546\n",
      "âœ… wgEncodeAwgTfbsBroadOsteoblCtcfUniPk: train_acc=0.9151, test_acc=0.8954\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsHaibA549Atf3V0422111Etoh02UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.6108 | Train Acc: 0.6914 | Val Loss: 0.5324 | Val Acc: 0.7325 | Val ROC-AUC: 0.8171\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.4679 | Train Acc: 0.7732 | Val Loss: 0.5211 | Val Acc: 0.7407 | Val ROC-AUC: 0.8268\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.3903 | Train Acc: 0.8213 | Val Loss: 0.5377 | Val Acc: 0.7403 | Val ROC-AUC: 0.8287\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3197 | Train Acc: 0.8664 | Val Loss: 0.5354 | Val Acc: 0.7432 | Val ROC-AUC: 0.8311\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2472 | Train Acc: 0.9025 | Val Loss: 0.5727 | Val Acc: 0.7388 | Val ROC-AUC: 0.8284\n",
      "âœ… Final Test | Loss: 0.5951 | Acc: 0.7314 | ROC-AUC: 0.8148\n",
      "âœ… wgEncodeAwgTfbsHaibA549Atf3V0422111Etoh02UniPk: train_acc=0.9025, test_acc=0.7314\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsHaibA549Bcl3V0422111Etoh02UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.5779 | Train Acc: 0.7249 | Val Loss: 0.4994 | Val Acc: 0.7432 | Val ROC-AUC: 0.8331\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.4547 | Train Acc: 0.7885 | Val Loss: 0.4992 | Val Acc: 0.7474 | Val ROC-AUC: 0.8333\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.3855 | Train Acc: 0.8295 | Val Loss: 0.5019 | Val Acc: 0.7482 | Val ROC-AUC: 0.8316\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3205 | Train Acc: 0.8606 | Val Loss: 0.5156 | Val Acc: 0.7549 | Val ROC-AUC: 0.8287\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2610 | Train Acc: 0.8927 | Val Loss: 0.5518 | Val Acc: 0.7378 | Val ROC-AUC: 0.8183\n",
      "âœ… Final Test | Loss: 0.5579 | Acc: 0.7440 | ROC-AUC: 0.8240\n",
      "âœ… wgEncodeAwgTfbsHaibA549Bcl3V0422111Etoh02UniPk: train_acc=0.8927, test_acc=0.7440\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsHaibA549Creb1sc240V0416102Dex100nmUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.5310 | Train Acc: 0.7461 | Val Loss: 0.4536 | Val Acc: 0.7859 | Val ROC-AUC: 0.8705\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.4204 | Train Acc: 0.8063 | Val Loss: 0.4355 | Val Acc: 0.8028 | Val ROC-AUC: 0.8819\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.3668 | Train Acc: 0.8367 | Val Loss: 0.4224 | Val Acc: 0.8046 | Val ROC-AUC: 0.8865\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.3188 | Train Acc: 0.8615 | Val Loss: 0.4314 | Val Acc: 0.7976 | Val ROC-AUC: 0.8823\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.2816 | Train Acc: 0.8799 | Val Loss: 0.4422 | Val Acc: 0.7940 | Val ROC-AUC: 0.8795\n",
      "âœ… Final Test | Loss: 0.4343 | Acc: 0.8043 | ROC-AUC: 0.8844\n",
      "âœ… wgEncodeAwgTfbsHaibA549Creb1sc240V0416102Dex100nmUniPk: train_acc=0.8799, test_acc=0.8043\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsHaibA549Ctcfsc5916Pcr1xDex100nmUniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.2088 | Train Acc: 0.9192 | Val Loss: 0.1521 | Val Acc: 0.9458 | Val ROC-AUC: 0.9864\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.1540 | Train Acc: 0.9430 | Val Loss: 0.1499 | Val Acc: 0.9460 | Val ROC-AUC: 0.9865\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.1348 | Train Acc: 0.9510 | Val Loss: 0.1489 | Val Acc: 0.9431 | Val ROC-AUC: 0.9865\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.1257 | Train Acc: 0.9534 | Val Loss: 0.1484 | Val Acc: 0.9452 | Val ROC-AUC: 0.9865\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.1164 | Train Acc: 0.9569 | Val Loss: 0.1554 | Val Acc: 0.9452 | Val ROC-AUC: 0.9863\n",
      "âœ… Final Test | Loss: 0.1543 | Acc: 0.9425 | ROC-AUC: 0.9864\n",
      "âœ… wgEncodeAwgTfbsHaibA549Ctcfsc5916Pcr1xDex100nmUniPk: train_acc=0.9569, test_acc=0.9425\n",
      "ðŸ”„ Processing folder: wgEncodeAwgTfbsHaibA549Ctcfsc5916Pcr1xEtoh02UniPk\n",
      "ðŸ”„ Epoch 1/5 started...\n",
      "ðŸ“ˆ Epoch 1/5 | Train Loss: 0.1618 | Train Acc: 0.9406 | Val Loss: 0.1392 | Val Acc: 0.9536 | Val ROC-AUC: 0.9882\n",
      "ðŸ”„ Epoch 2/5 started...\n",
      "ðŸ“ˆ Epoch 2/5 | Train Loss: 0.1375 | Train Acc: 0.9496 | Val Loss: 0.1411 | Val Acc: 0.9523 | Val ROC-AUC: 0.9877\n",
      "ðŸ”„ Epoch 3/5 started...\n",
      "ðŸ“ˆ Epoch 3/5 | Train Loss: 0.1223 | Train Acc: 0.9557 | Val Loss: 0.1499 | Val Acc: 0.9494 | Val ROC-AUC: 0.9869\n",
      "ðŸ”„ Epoch 4/5 started...\n",
      "ðŸ“ˆ Epoch 4/5 | Train Loss: 0.1139 | Train Acc: 0.9578 | Val Loss: 0.1473 | Val Acc: 0.9475 | Val ROC-AUC: 0.9863\n",
      "ðŸ”„ Epoch 5/5 started...\n",
      "ðŸ“ˆ Epoch 5/5 | Train Loss: 0.1057 | Train Acc: 0.9612 | Val Loss: 0.1432 | Val Acc: 0.9506 | Val ROC-AUC: 0.9863\n",
      "âœ… Final Test | Loss: 0.1423 | Acc: 0.9488 | ROC-AUC: 0.9866\n",
      "âœ… wgEncodeAwgTfbsHaibA549Ctcfsc5916Pcr1xEtoh02UniPk: train_acc=0.9612, test_acc=0.9488\n",
      "âœ… Metrics saved to ../Models/50_W2V.xlsx\n",
      "âœ… Final fine-tuned model saved to Models/50_W2V.pt\n"
     ]
    }
   ],
   "source": [
    "for idx, row in results_df.iloc[:50].iterrows():\n",
    "    folder_name = row[\"folder_name\"]\n",
    "    train_path = row[\"train_path\"]\n",
    "    test_path = row[\"test_path\"]\n",
    "\n",
    "    print(f\"ðŸ”„ Processing folder: {folder_name}\")\n",
    "\n",
    "    # Load dataframes\n",
    "    train_df = load_sequence_data(train_path)\n",
    "    test_df = load_sequence_data(test_path)\n",
    "\n",
    "    # âœ… prepare_kmer_loaders handles tokenization + valid split\n",
    "    train_loader, valid_loader, test_loader = prepare_kmer_loaders(\n",
    "        train_df[\"sequence\"].tolist(),\n",
    "        train_df[\"label\"].values,\n",
    "        test_df[\"sequence\"].tolist(),\n",
    "        test_df[\"label\"].values,\n",
    "        vocab,\n",
    "        k=6,\n",
    "        stride=1,\n",
    "        max_len=96,\n",
    "        batch_size=32,\n",
    "    )\n",
    "\n",
    "    # Fine-tune model\n",
    "    model, last_epoch, test_metrics = train_and_evaluate(\n",
    "        model,\n",
    "        train_loader,\n",
    "        valid_loader,\n",
    "        test_loader,\n",
    "        device,\n",
    "        epochs=5,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "    )\n",
    "\n",
    "    # âœ… Log metrics\n",
    "    excel_df.at[idx, \"folder_name\"] = folder_name\n",
    "    excel_df.at[idx, \"train_accuracy\"] = last_epoch[\"train_acc\"]\n",
    "    excel_df.at[idx, \"test_accuracy\"] = test_metrics[\"test_acc\"]\n",
    "    excel_df.at[idx, \"pr-roc\"] = test_metrics[\"test_roc_auc\"]\n",
    "    excel_df.at[idx, \"pr-auc\"] = test_metrics[\"test_pr_auc\"]\n",
    "\n",
    "    print(\n",
    "        f\"âœ… {folder_name}: train_acc={last_epoch['train_acc']:.4f}, test_acc={test_metrics['test_acc']:.4f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# âœ… Save updated Excel\n",
    "excel_df.iloc[: idx + 1].to_excel(excel_path, index=False)\n",
    "print(f\"âœ… Metrics saved to {excel_path}\")\n",
    "\n",
    "# âœ… Save the final fine-tuned model\n",
    "torch.save(\n",
    "    model.state_dict(), \"../Models/50_W2V.pt\"\n",
    ")  #  <---  Fine tuned model after 50 folders.\n",
    "print(\"âœ… Final fine-tuned model saved to Models/50_W2V.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa0b37a",
   "metadata": {},
   "source": [
    "# USER INPUT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa4840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from k_mer_data_loader import prepare_kmer_loaders\n",
    "from initialize_results_df import initialize_results_df\n",
    "from load_sequence_data import load_sequence_data\n",
    "from kmer_2_vec import (\n",
    "    get_kmer_list,\n",
    "    train_word2vec,\n",
    "    build_vocab,\n",
    "    build_embedding_matrix,\n",
    ")\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from kmer_2_vec import SimpleCNN, train_and_evaluate, predict_W2V_sequence\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c5707",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../Models/50_W2V.pt\"\n",
    "w2v_path = \"../Models/kmer2vec_k_6_s_1.model\"\n",
    "\n",
    "w2v_model = Word2Vec.load(w2v_path)\n",
    "vocab = build_vocab(k=6)\n",
    "pretrained_embeddings = {\n",
    "    kmer: w2v_model.wv[kmer] for kmer in w2v_model.wv.index_to_key\n",
    "}\n",
    "embedding_matrix = build_embedding_matrix(\n",
    "    vocab, pretrained_embeddings, embedding_dim=128\n",
    ")\n",
    "model = SimpleCNN(embedding_matrix, freeze_embed=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039af8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_27884\\1541938869.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: TFBS (Confidence: 99.58%)\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN(embedding_matrix, freeze_embed=True)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "seq = input(\"Enter a DNA sequence: \").strip()\n",
    "label, conf = predict_W2V_sequence(\n",
    "    model, w2v_model, vocab, seq, k=6, stride=1, max_len=96, device=\"cpu\"\n",
    ")\n",
    "print(f\"Prediction: {label} (Confidence: {conf}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99465e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
